{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplifiedModel import LogisticRegressor,accuracy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtest_LogisticRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mtest_LogisticRegressor\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Initialize and train the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegressor(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Predict on the training data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\OneDrive\\Desktop\\Info\\programmation\\python\\machine learning\\supervised\\classifier\\logistic regression\\logistic_regression\\simplifiedModel.py:33\u001b[0m, in \u001b[0;36mLogisticRegressor.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     31\u001b[0m gradient \u001b[38;5;241m=\u001b[39m x_with_bias\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (y \u001b[38;5;241m-\u001b[39m y_predict_proba)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# update weights :\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m gradient\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_LogisticRegressor():\n",
    "    # Create a simple dataset\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    y = np.array([0, 0, 1, 1])\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LogisticRegressor(learning_rate=0.3, max_iter=10000,random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict on the training data\n",
    "    predictions = model.predict(X)\n",
    "    print(predictions)\n",
    "   \n",
    "test_LogisticRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess_data(X, y):\n",
    "    # Remove rows with missing values\n",
    "    X = X.dropna()\n",
    "    y = y.dropna()\n",
    "\n",
    "    # Encode the target variable\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y)\n",
    "\n",
    "    # Normalize the features to the range [0, 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=LogisticRegressor()\n",
    "df=pd.read_csv('../fake_bills.csv',sep=';')\n",
    "df=df.dropna()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_train=df.head(1000)\n",
    "x=df_train.drop(['is_genuine'],axis=1)\n",
    "y=df_train['is_genuine']\n",
    "x,y=preprocess_data(x,y)\n",
    "model2.fit(x,y)\n",
    "df_test=df.tail(400)\n",
    "x_test,y_test=preprocess_data(df_test.drop(['is_genuine'],axis=1),df_test['is_genuine'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.99\n"
     ]
    }
   ],
   "source": [
    "model_accuracy=accuracy(y_test,model2.predict(x_test))\n",
    "print(f'accuracy is {model_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
